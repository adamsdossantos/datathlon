{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b06fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\FIAP\\5_MLOps\\7_Tech_Challenge_5\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "Downloading artifacts:  28%|██▊       | 5/18 [00:01<00:04,  2.61it/s]\n",
      "Downloading artifacts:  83%|████████▎ | 15/18 [00:18<00:00,  4.75it/s]WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2.storage.cloud.databricks.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /api/2.0/fs/files/Models/workspace/default/sentencetransformermodel/1/artifacts/distiluse-base-multilingual-cased-v1/tokenizer.json?v=1&workspaceId=584718778288400&wkt=cp&userId=70444113622605&X-Databricks-TTL=1800000&X-Databricks-Consumer-Network-Zone=internet&sn=oregon-prod&X-Databricks-Key-Version=01f067d8-8b63-13da-8db3-8f8247a02432&X-Databricks-Issued=20250723T203929Z&X-Databricks-Signature=AU1lcfxiQh7QBTK4dcTzgyneL4JAdptYROUrikepR-kx3iybIA\n",
      "\n",
      "\u001b[A\n",
      "Downloading artifacts:  89%|████████▉ | 16/18 [00:24<00:06,  3.27s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading C:\\Users\\adams\\AppData\\Local\\Temp\\tmp7ntyj8_y\\artifacts/distiluse-base-multilingual-cased-v1/model.safetensors:  78%|███████▊  | 400M/514M [02:13<00:37, 3.15MiB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading C:\\Users\\adams\\AppData\\Local\\Temp\\tmp7ntyj8_y\\python_model.pkl:  97%|█████████▋| 500M/517M [02:17<00:04, 3.81MiB/s]\n",
      "Downloading artifacts: 100%|██████████| 18/18 [03:36<00:00, 12.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV MLFLOW_TRACKING_URI: databricks\n",
      "Current MLflow tracking URI: databricks\n",
      "Current MLflow registry URI: databricks-uc\n",
      "MLflow tracking URI: databricks\n",
      "MLflow registry URI: databricks-uc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import traceback\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections_mongo import collection_applicants, collection_vagas\n",
    "from collection_qdrant import qdrant\n",
    "from tf_idf_cache import cache_applicants, cache_vagas\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"app\\\\vectorizer.pkl\", \"rb\") as f:\n",
    "#     vectorizer_new = pickle.load(f)\n",
    "\n",
    "\n",
    "# model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_PATH\", \"/Users/contact.adams.souza@gmail.com/Matching_Experiment\"))\n",
    "\n",
    "\n",
    "vectorizer_new = mlflow.sklearn.load_model(\"models:/workspace.default.tfidfvectorizer@champion\")\n",
    "model = mlflow.pyfunc.load_model(\"models:/workspace.default.sentencetransformermodel@champion\")\n",
    "\n",
    "print(f\"ENV MLFLOW_TRACKING_URI: {os.getenv('MLFLOW_TRACKING_URI')}\")\n",
    "print(f\"Current MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Current MLflow registry URI: {mlflow.get_registry_uri()}\")\n",
    "\n",
    "def vagas_match(job_id:str, model:object=model, vectorizer:object = vectorizer_new, alpha:float=0.3, top_n:int=5, version:str=\"1.0\"):\n",
    "    \"\"\"\n",
    "    Analisa o corpus das vagas e associa aos top-n candidatos com mais adequação\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # coletando dados do MongoDB\n",
    "        job_doc = collection_vagas.find_one({\"_id\":str(job_id)}, {\n",
    "                                            \"_id\": 1,\n",
    "                                            \"informacoes_basicas.cliente\":1,\n",
    "                                            \"informacoes_basicas.titulo_vaga\":1 ,\n",
    "                                            \"perfil_vaga.pais\":1,\n",
    "                                            \"perfil_vaga.estado\":1,\n",
    "                                            \"perfil_vaga.cidade\":1,\n",
    "                                            \"perfil_vaga.nivel profissional\":1,\n",
    "                                            \"perfil_vaga.nivel_academico\" :1,\n",
    "                                            \"perfil_vaga.nivel_ingles\":1,\n",
    "                                            \"perfil_vaga.nivel_espanhol\":1,\n",
    "                                            \"perfil_vaga.areas_atuacao\":1,\n",
    "                                            \"perfil_vaga.principais_atividades\":1\n",
    "                                            })\n",
    "\n",
    "        if not job_doc:\n",
    "            return []\n",
    "\n",
    "        id = job_doc.get('_id', \"\")\n",
    "        cliente = job_doc.get('informacoes_basicas', {}).get('cliente',\"\")\n",
    "        titulo_vaga = job_doc.get('informacoes_basicas', {}).get('titulo_vaga', \"\")\n",
    "        solicitante_cliente = job_doc.get('informacoes_basicas', {}).get(\"solicitante_cliente\",\"\"),\n",
    "        pais = job_doc.get('perfil_vaga', {}).get(\"pais\",\"\")\n",
    "        estado = job_doc.get('perfil_vaga', {}).get(\"estado\",\"\")\n",
    "        cidade = job_doc.get('perfil_vaga', {}).get(\"cidade\",\"\")\n",
    "        n_prof = job_doc.get('perfil_vaga', {}).get(\"nivel profissional\",\"\")\n",
    "        n_acad = job_doc.get('perfil_vaga', {}).get(\"nivel_academico\",\"\")\n",
    "        n_en = job_doc.get('perfil_vaga', {}).get(\"nivel_ingles\",\"\")\n",
    "        n_es = job_doc.get('perfil_vaga', {}).get(\"nivel_espanhol\",\"\")\n",
    "        area = job_doc.get('perfil_vaga', {}).get(\"areas_atuacao\",\"\")\n",
    "        atividades = job_doc.get('perfil_vaga', {}).get(\"principais_atividades\",\"\")\n",
    "\n",
    "        # corpus para embedding\n",
    "        job_text = f\"{id} {pais} {estado} {cidade} {n_prof} {n_acad} {n_en} {n_es} {area} {atividades}\"\n",
    "\n",
    "        # vectorização para tf-idf + consine similarity\n",
    "        vectorized_job = vectorizer.transform([job_text])\n",
    "        similar_job = cosine_similarity(cache_applicants[\"vectorized\"], vectorized_job)\n",
    "\n",
    "        # dicionario de similaridade tf-idf\n",
    "        tfidf_scores = {\n",
    "            str(cache_applicants[\"id_applicants\"][i]): similar_job[i] for i in range(len(similar_job))\n",
    "        }\n",
    "\n",
    "        # vectorização do corpus para sentence transformer + Qdrant\n",
    "        qdrant_vector_job = model.predict([job_text])[0].tolist()\n",
    "        results = qdrant.query_points(collection_name=\"applicants\", query=qdrant_vector_job, limit=100)\n",
    "\n",
    "        # normalizando os scores\n",
    "        tfidf_max = max(tfidf_scores.values()) if tfidf_scores else 1\n",
    "        tfidf_scores = {k: v / tfidf_max for k, v in tfidf_scores.items()}\n",
    "\n",
    "        qdrant_scores = {str(item.payload[\"_id\"]):item.score for item in results.points}\n",
    "\n",
    "        qdrant_max = max(qdrant_scores.values()) if qdrant_scores else 1\n",
    "        qdrant_scores = {k: v / qdrant_max for k, v in qdrant_scores.items()}\n",
    "\n",
    "        #combinando os scores\n",
    "        combined_scores = []\n",
    "        for _id in set(tfidf_scores) & set(qdrant_scores):\n",
    "            combined = alpha * tfidf_scores[_id] + (1- alpha) * qdrant_scores[_id]\n",
    "            combined_scores.append((_id,combined.item()))\n",
    "\n",
    "        # sorting and display os scores combinados\n",
    "        combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_matches = combined_scores[:top_n]\n",
    "\n",
    "        # Log parameters\n",
    "        if mlflow.active_run() is None:\n",
    "            with mlflow.start_run(run_name=\"Vagas Match - SUCCESS\") as run:\n",
    "                mlflow.log_param(\"job_id\", job_id)\n",
    "                mlflow.log_param(\"job_id\", job_id)\n",
    "                mlflow.log_param(\"alpha\", alpha)\n",
    "                mlflow.log_param(\"top_n\", top_n)\n",
    "                mlflow.log_param(\"version\", version)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"tfidf_max\", tfidf_max.item() if hasattr(tfidf_max, 'item') else tfidf_max)\n",
    "                mlflow.log_metric(\"qdrant_max\", qdrant_max)\n",
    "                if combined_scores:\n",
    "                    mlflow.log_metric(\"combined_max\", max(combined_scores, key=lambda x: x[1])[1])\n",
    "\n",
    "                #log models\n",
    "                #mlflow.sklearn.log_model(sk_model=vectorizer_new, name=\"TFIDFVectorizer\")\n",
    "                #mlflow.sentence_transformers.log_model(model=model, name=\"SentenceTransformerModel\")\n",
    "\n",
    "                # Set tags\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "\n",
    "        # payload do Qdrant\n",
    "        qdrant_map = {\n",
    "            str(p.payload[\"_id\"]): p.payload for p in results.points\n",
    "        }\n",
    "\n",
    "        # resposta\n",
    "        vaga_info = {\n",
    "            \"_id\": id,\n",
    "            \"titulo_vaga\": titulo_vaga,\n",
    "            \"cliente\": cliente,\n",
    "            \"solicitante_cliente\": solicitante_cliente,\n",
    "        }\n",
    "\n",
    "        top_applicants = []\n",
    "        for _id, score in top_matches:\n",
    "            payload = qdrant_map.get(_id, {})\n",
    "            top_applicants.append({\n",
    "                \"_id\" : _id,\n",
    "                \"nome\" : payload.get(\"nome\", \"\"),\n",
    "                \"email\" : payload.get(\"email\", \"\"),\n",
    "                \"telefone\":payload.get(\"telefone\",\"\"),\n",
    "                \"score\" : round(score, 3)\n",
    "            })\n",
    "\n",
    "        output = [{\"vaga\":vaga_info, \"top_applicants\":top_applicants}]\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        with mlflow.start_run(run_name=\"Vagas Match - FAILED\") as run:\n",
    "            mlflow.log_param(\"job_id\", job_id)\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"top_n\", top_n)\n",
    "            mlflow.log_param(\"version\", version)\n",
    "            mlflow.set_tag(\"status\", \"failed\")\n",
    "            mlflow.set_tag(\"error_message\", str(e))\n",
    "            mlflow.set_tag(\"error_traceback\", traceback.format_exc())\n",
    "        raise e\n",
    "\n",
    "def applicants_match(applicant_id:str, model:object=model, vectorizer:object=vectorizer_new, alpha:float=0.3, top_n:int=5, version:str=\"1.0\"):\n",
    "    \"\"\"\n",
    "    Analisa o corpus dos candidatos e os associa às top-n vagas com mais adequação\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # coletando dados do MongoDB\n",
    "        applicants_doc = collection_applicants.find_one({\"_id\":str(applicant_id)}, {\n",
    "                                                        \"_id\": 1,\n",
    "                                                        \"infos_basicas.nome\":1,\n",
    "                                                        \"infos_basicas.email\":1,\n",
    "                                                        \"infos_basicas.telefone\":1,\n",
    "                                                        \"informacoes_profissionais.certificacoes\":1,\n",
    "                                                        \"formacao_e_idiomas.nivel_ingles\": 1,\n",
    "                                                        \"formacao_e_idiomas.nivel_espanhol\":1,\n",
    "                                                        \"cv_pt\":1\n",
    "                                                        })\n",
    "\n",
    "        if not applicants_doc:\n",
    "            return []\n",
    "\n",
    "        id = applicants_doc.get('_id', \"\")\n",
    "        nome = applicants_doc.get('infos_basicas', {}).get(\"nome\",\"\")\n",
    "        email = applicants_doc.get('infos_basicas', {}).get(\"email\",\"\")\n",
    "        telefone = applicants_doc.get('infos_basicas', {}).get(\"telefone\", \"\")\n",
    "        certification = applicants_doc.get('informacoes_profissionais', {}).get(\"certificacoes\",\"\")\n",
    "        education_en = applicants_doc.get('formacao_e_idiomas', {}).get(\"nivel_ingles\",\"\")\n",
    "        education_es = applicants_doc.get('formacao_e_idiomas', {}).get(\"nivel_espanhol\",\"\")\n",
    "        cv = applicants_doc.get('cv_pt', \"\")\n",
    "\n",
    "        # corpus para embedding\n",
    "        applicant_text = f\"{certification} {education_en} {education_es} {cv}\"\n",
    "\n",
    "        # vectorização para tf-idf + consine similarity\n",
    "        vectorized_applicant = vectorizer.transform([applicant_text])\n",
    "        similar_applicant = cosine_similarity(cache_vagas[\"vectorized\"], vectorized_applicant)\n",
    "\n",
    "        # dicionario de similaridade tf-idf\n",
    "        tfidf_scores = {\n",
    "            str(cache_vagas[\"id_vagas\"][i]):similar_applicant[i] for i in range(len(similar_applicant))\n",
    "        }\n",
    "\n",
    "        # vectorização do corpus para sentence transformer + Qdrant\n",
    "        qdrant_vector_applicant = model.predict([applicant_text])[0].tolist()\n",
    "        results = qdrant.query_points(collection_name=\"vagas\", query=qdrant_vector_applicant, limit=100)\n",
    "\n",
    "        # normalizando os scores\n",
    "        tfidf_max = max(tfidf_scores.values()) if tfidf_scores else 1\n",
    "        tfidf_scores = {k: v / tfidf_max for k, v in tfidf_scores.items()}\n",
    "\n",
    "        qdrant_scores = {str(item.payload[\"_id\"]):item.score for item in results.points}\n",
    "\n",
    "        qdrant_max = max(qdrant_scores.values()) if qdrant_scores else 1\n",
    "        qdrant_scores = {k: v / qdrant_max for k, v in qdrant_scores.items()}\n",
    "\n",
    "        #combinando os scores\n",
    "        combined_scores = []\n",
    "        for _id in set(tfidf_scores) & set(qdrant_scores):\n",
    "            combined = alpha * tfidf_scores[_id] + (1- alpha) * qdrant_scores[_id]\n",
    "            combined_scores.append((_id,combined.item()))\n",
    "\n",
    "        # sorting and display os scores combinados\n",
    "        combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_matches = combined_scores[:top_n]\n",
    "\n",
    "        # tracking com MLFlow\n",
    "        if mlflow.active_run() is None:\n",
    "            with mlflow.start_run(run_name=\"Applicants Match - SUCCESS\") as run:\n",
    "            # Log parameters\n",
    "                mlflow.log_param(\"applicant_id\", applicant_id)\n",
    "                mlflow.log_param(\"alpha\", alpha)\n",
    "                mlflow.log_param(\"top_n\", top_n)\n",
    "                mlflow.log_param(\"version\", version)\n",
    "                #mlflow.log_param(\"model_name_qdrant\",model)\n",
    "                #mlflow.log_param(\"model_name_tfidf\",vectorizer)\n",
    "\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"tfidf_max\", tfidf_max.item() if hasattr(tfidf_max, 'item') else tfidf_max)\n",
    "                mlflow.log_metric(\"qdrant_max\", qdrant_max)\n",
    "                if combined_scores:\n",
    "                    mlflow.log_metric(\"combined_max\", max(combined_scores, key=lambda x: x[1])[1])\n",
    "                \n",
    "                #log models\n",
    "                #mlflow.sklearn.log_model(sk_model=vectorizer_new, name=\"TFIDFVectorizer\")\n",
    "                #mlflow.sentence_transformers.log_model(model=model, name=\"SentenceTransformerModel\")\n",
    "\n",
    "                # Set tags\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "\n",
    "        # payload do Qdrant\n",
    "        qdrant_map = {\n",
    "            str(p.payload[\"_id\"]): p.payload for p in results.points\n",
    "        }\n",
    "\n",
    "        # resposta\n",
    "        applicant_info = {\n",
    "                \"_id\" : id,\n",
    "                \"nome\" : nome,\n",
    "                \"email\" : email,\n",
    "                \"telefone\":telefone,\n",
    "        }\n",
    "\n",
    "        top_vagas = []\n",
    "        for _id, score in top_matches:\n",
    "            payload = qdrant_map.get(_id, {})\n",
    "            top_vagas.append({\n",
    "                 \"_id\": _id,\n",
    "                \"titulo_vaga\": payload.get(\"titulo_vaga\", \"\"),\n",
    "                \"cliente\": payload.get(\"cliente\", \"\"),\n",
    "                \"score\": round(score, 3)\n",
    "            })\n",
    "\n",
    "        output = [{\"applicant\":applicant_info, \"top_vagas\":top_vagas}]\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        with mlflow.start_run(run_name=\"Applicants Match - FAILED\") as run:\n",
    "            mlflow.log_param(\"applicant_id\", applicant_id)\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"top_n\", top_n)\n",
    "            mlflow.log_param(\"version\", version)\n",
    "            mlflow.set_tag(\"status\", \"failed\")\n",
    "            mlflow.set_tag(\"error_message\", str(e))\n",
    "            mlflow.set_tag(\"error_traceback\", traceback.format_exc())\n",
    "        raise e\n",
    "\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow registry URI: {mlflow.get_registry_uri()}\")\n",
    "\n",
    "# Add this debug line to your matching_functions.py:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f912b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track uri\n",
      "registry uri\n",
      "tokens\n",
      "experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/857129996570473', creation_time=1753270783714, experiment_id='857129996570473', last_update_time=1753297708867, lifecycle_stage='active', name='/Users/contact.adams.souza@gmail.com/Matching_Experiment', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n",
       " 'mlflow.experiment.sourceName': '/Users/contact.adams.souza@gmail.com/Matching_Experiment',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'contact.adams.souza@gmail.com',\n",
       " 'mlflow.ownerId': '70444113622605'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\"track uri\")\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "print(\"registry uri\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "print(\"tokens\")\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "#mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_PATH\"))\n",
    "print(\"experiment\")\n",
    "mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_PATH\", \"/Users/contact.adams.souza@gmail.com/Matching_Experiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e145c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "import mlflow\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from app.collections_mongo import collection_applicants, collection_vagas\n",
    "from app.collection_qdrant import qdrant\n",
    "from app.tf_idf_cache import cache_applicants, cache_vagas\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# with open(\"app\\\\vectorizer.pkl\", \"rb\") as f:\n",
    "#     vectorizer_new = pickle.load(f)\n",
    "\n",
    "# model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "# === Load environment variables from .env ===\n",
    "load_dotenv()\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_PATH\", \"/Users/contact.adams.souza@gmail.com/Matching_Experiment\"))\n",
    "\n",
    "# Add a small delay to ensure authentication is fully established\n",
    "time.sleep(5)\n",
    "\n",
    "vectorizer_new = mlflow.sklearn.load_model(\"models:/workspace.default.tfidfvectorizer@champion\")\n",
    "model = mlflow.pyfunc.load_model(\"models:/workspace.default.sentencetransformermodel@champion\")\n",
    "\n",
    "\n",
    "def vagas_match(job_id:str, model:object=model, vectorizer:object = vectorizer_new, alpha:float=0.3, top_n:int=5, version:str=\"1.0\"):\n",
    "    \"\"\"\n",
    "    Analisa o corpus das vagas e associa aos top-n candidatos com mais adequação\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # coletando dados do MongoDB\n",
    "        job_doc = collection_vagas.find_one({\"_id\":str(job_id)}, {\n",
    "                                            \"_id\": 1,\n",
    "                                            \"informacoes_basicas.cliente\":1,\n",
    "                                            \"informacoes_basicas.titulo_vaga\":1 ,\n",
    "                                            \"perfil_vaga.pais\":1,\n",
    "                                            \"perfil_vaga.estado\":1,\n",
    "                                            \"perfil_vaga.cidade\":1,\n",
    "                                            \"perfil_vaga.nivel profissional\":1,\n",
    "                                            \"perfil_vaga.nivel_academico\" :1,\n",
    "                                            \"perfil_vaga.nivel_ingles\":1,\n",
    "                                            \"perfil_vaga.nivel_espanhol\":1,\n",
    "                                            \"perfil_vaga.areas_atuacao\":1,\n",
    "                                            \"perfil_vaga.principais_atividades\":1\n",
    "                                            })\n",
    "\n",
    "        if not job_doc:\n",
    "            return []\n",
    "\n",
    "        id = job_doc.get('_id', \"\")\n",
    "        cliente = job_doc.get('informacoes_basicas', {}).get('cliente',\"\")\n",
    "        titulo_vaga = job_doc.get('informacoes_basicas', {}).get('titulo_vaga', \"\")\n",
    "        solicitante_cliente = job_doc.get('informacoes_basicas', {}).get(\"solicitante_cliente\",\"\"),\n",
    "        pais = job_doc.get('perfil_vaga', {}).get(\"pais\",\"\")\n",
    "        estado = job_doc.get('perfil_vaga', {}).get(\"estado\",\"\")\n",
    "        cidade = job_doc.get('perfil_vaga', {}).get(\"cidade\",\"\")\n",
    "        n_prof = job_doc.get('perfil_vaga', {}).get(\"nivel profissional\",\"\")\n",
    "        n_acad = job_doc.get('perfil_vaga', {}).get(\"nivel_academico\",\"\")\n",
    "        n_en = job_doc.get('perfil_vaga', {}).get(\"nivel_ingles\",\"\")\n",
    "        n_es = job_doc.get('perfil_vaga', {}).get(\"nivel_espanhol\",\"\")\n",
    "        area = job_doc.get('perfil_vaga', {}).get(\"areas_atuacao\",\"\")\n",
    "        atividades = job_doc.get('perfil_vaga', {}).get(\"principais_atividades\",\"\")\n",
    "\n",
    "        # corpus para embedding\n",
    "        job_text = f\"{id} {pais} {estado} {cidade} {n_prof} {n_acad} {n_en} {n_es} {area} {atividades}\"\n",
    "\n",
    "        # vectorização para tf-idf + consine similarity\n",
    "        vectorized_job = vectorizer.transform([job_text])\n",
    "        similar_job = cosine_similarity(cache_applicants[\"vectorized\"], vectorized_job)\n",
    "\n",
    "        # dicionario de similaridade tf-idf\n",
    "        tfidf_scores = {\n",
    "            str(cache_applicants[\"id_applicants\"][i]): similar_job[i] for i in range(len(similar_job))\n",
    "        }\n",
    "\n",
    "        # vectorização do corpus para sentence transformer + Qdrant\n",
    "        qdrant_vector_job = model.predict([job_text])[0].tolist()\n",
    "        results = qdrant.query_points(collection_name=\"applicants\", query=qdrant_vector_job, limit=100)\n",
    "\n",
    "        # normalizando os scores\n",
    "        tfidf_max = max(tfidf_scores.values()) if tfidf_scores else 1\n",
    "        tfidf_scores = {k: v / tfidf_max for k, v in tfidf_scores.items()}\n",
    "\n",
    "        qdrant_scores = {str(item.payload[\"_id\"]):item.score for item in results.points}\n",
    "\n",
    "        qdrant_max = max(qdrant_scores.values()) if qdrant_scores else 1\n",
    "        qdrant_scores = {k: v / qdrant_max for k, v in qdrant_scores.items()}\n",
    "\n",
    "        #combinando os scores\n",
    "        combined_scores = []\n",
    "        for _id in set(tfidf_scores) & set(qdrant_scores):\n",
    "            combined = alpha * tfidf_scores[_id] + (1- alpha) * qdrant_scores[_id]\n",
    "            combined_scores.append((_id,combined.item()))\n",
    "\n",
    "        # sorting and display os scores combinados\n",
    "        combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_matches = combined_scores[:top_n]\n",
    "\n",
    "        # Log parameters\n",
    "        if mlflow.active_run() is None:\n",
    "            with mlflow.start_run(run_name=\"Vagas Match - SUCCESS\") as run:\n",
    "                mlflow.log_param(\"job_id\", job_id)\n",
    "                mlflow.log_param(\"job_id\", job_id)\n",
    "                mlflow.log_param(\"alpha\", alpha)\n",
    "                mlflow.log_param(\"top_n\", top_n)\n",
    "                mlflow.log_param(\"version\", version)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"tfidf_max\", tfidf_max.item() if hasattr(tfidf_max, 'item') else tfidf_max)\n",
    "                mlflow.log_metric(\"qdrant_max\", qdrant_max)\n",
    "                if combined_scores:\n",
    "                    mlflow.log_metric(\"combined_max\", max(combined_scores, key=lambda x: x[1])[1])\n",
    "\n",
    "                #log models\n",
    "                #mlflow.sklearn.log_model(sk_model=vectorizer_new, name=\"TFIDFVectorizer\")\n",
    "                #mlflow.sentence_transformers.log_model(model=model, name=\"SentenceTransformerModel\")\n",
    "\n",
    "                # Set tags\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "\n",
    "        # payload do Qdrant\n",
    "        qdrant_map = {\n",
    "            str(p.payload[\"_id\"]): p.payload for p in results.points\n",
    "        }\n",
    "\n",
    "        # resposta\n",
    "        vaga_info = {\n",
    "            \"_id\": id,\n",
    "            \"titulo_vaga\": titulo_vaga,\n",
    "            \"cliente\": cliente,\n",
    "            \"solicitante_cliente\": solicitante_cliente,\n",
    "        }\n",
    "\n",
    "        top_applicants = []\n",
    "        for _id, score in top_matches:\n",
    "            payload = qdrant_map.get(_id, {})\n",
    "            top_applicants.append({\n",
    "                \"_id\" : _id,\n",
    "                \"nome\" : payload.get(\"nome\", \"\"),\n",
    "                \"email\" : payload.get(\"email\", \"\"),\n",
    "                \"telefone\":payload.get(\"telefone\",\"\"),\n",
    "                \"score\" : round(score, 3)\n",
    "            })\n",
    "\n",
    "        output = [{\"vaga\":vaga_info, \"top_applicants\":top_applicants}]\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        with mlflow.start_run(run_name=\"Vagas Match - FAILED\") as run:\n",
    "            mlflow.log_param(\"job_id\", job_id)\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"top_n\", top_n)\n",
    "            mlflow.log_param(\"version\", version)\n",
    "            mlflow.set_tag(\"status\", \"failed\")\n",
    "            mlflow.set_tag(\"error_message\", str(e))\n",
    "            mlflow.set_tag(\"error_traceback\", traceback.format_exc())\n",
    "        raise e\n",
    "\n",
    "def applicants_match(applicant_id:str, model:object=model, vectorizer:object=vectorizer_new, alpha:float=0.3, top_n:int=5, version:str=\"1.0\"):\n",
    "    \"\"\"\n",
    "    Analisa o corpus dos candidatos e os associa às top-n vagas com mais adequação\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # coletando dados do MongoDB\n",
    "        applicants_doc = collection_applicants.find_one({\"_id\":str(applicant_id)}, {\n",
    "                                                        \"_id\": 1,\n",
    "                                                        \"infos_basicas.nome\":1,\n",
    "                                                        \"infos_basicas.email\":1,\n",
    "                                                        \"infos_basicas.telefone\":1,\n",
    "                                                        \"informacoes_profissionais.certificacoes\":1,\n",
    "                                                        \"formacao_e_idiomas.nivel_ingles\": 1,\n",
    "                                                        \"formacao_e_idiomas.nivel_espanhol\":1,\n",
    "                                                        \"cv_pt\":1\n",
    "                                                        })\n",
    "\n",
    "        if not applicants_doc:\n",
    "            return []\n",
    "\n",
    "        id = applicants_doc.get('_id', \"\")\n",
    "        nome = applicants_doc.get('infos_basicas', {}).get(\"nome\",\"\")\n",
    "        email = applicants_doc.get('infos_basicas', {}).get(\"email\",\"\")\n",
    "        telefone = applicants_doc.get('infos_basicas', {}).get(\"telefone\", \"\")\n",
    "        certification = applicants_doc.get('informacoes_profissionais', {}).get(\"certificacoes\",\"\")\n",
    "        education_en = applicants_doc.get('formacao_e_idiomas', {}).get(\"nivel_ingles\",\"\")\n",
    "        education_es = applicants_doc.get('formacao_e_idiomas', {}).get(\"nivel_espanhol\",\"\")\n",
    "        cv = applicants_doc.get('cv_pt', \"\")\n",
    "\n",
    "        # corpus para embedding\n",
    "        applicant_text = f\"{certification} {education_en} {education_es} {cv}\"\n",
    "\n",
    "        # vectorização para tf-idf + consine similarity\n",
    "        vectorized_applicant = vectorizer.transform([applicant_text])\n",
    "        similar_applicant = cosine_similarity(cache_vagas[\"vectorized\"], vectorized_applicant)\n",
    "\n",
    "        # dicionario de similaridade tf-idf\n",
    "        tfidf_scores = {\n",
    "            str(cache_vagas[\"id_vagas\"][i]):similar_applicant[i] for i in range(len(similar_applicant))\n",
    "        }\n",
    "\n",
    "        # vectorização do corpus para sentence transformer + Qdrant\n",
    "        qdrant_vector_applicant = model.predict([applicant_text])[0].tolist()\n",
    "        results = qdrant.query_points(collection_name=\"vagas\", query=qdrant_vector_applicant, limit=100)\n",
    "\n",
    "        # normalizando os scores\n",
    "        tfidf_max = max(tfidf_scores.values()) if tfidf_scores else 1\n",
    "        tfidf_scores = {k: v / tfidf_max for k, v in tfidf_scores.items()}\n",
    "\n",
    "        qdrant_scores = {str(item.payload[\"_id\"]):item.score for item in results.points}\n",
    "\n",
    "        qdrant_max = max(qdrant_scores.values()) if qdrant_scores else 1\n",
    "        qdrant_scores = {k: v / qdrant_max for k, v in qdrant_scores.items()}\n",
    "\n",
    "        #combinando os scores\n",
    "        combined_scores = []\n",
    "        for _id in set(tfidf_scores) & set(qdrant_scores):\n",
    "            combined = alpha * tfidf_scores[_id] + (1- alpha) * qdrant_scores[_id]\n",
    "            combined_scores.append((_id,combined.item()))\n",
    "\n",
    "        # sorting and display os scores combinados\n",
    "        combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_matches = combined_scores[:top_n]\n",
    "\n",
    "        # tracking com MLFlow\n",
    "        if mlflow.active_run() is None:\n",
    "            with mlflow.start_run(run_name=\"Applicants Match - SUCCESS\") as run:\n",
    "            # Log parameters\n",
    "                mlflow.log_param(\"applicant_id\", applicant_id)\n",
    "                mlflow.log_param(\"alpha\", alpha)\n",
    "                mlflow.log_param(\"top_n\", top_n)\n",
    "                mlflow.log_param(\"version\", version)\n",
    "                #mlflow.log_param(\"model_name_qdrant\",model)\n",
    "                #mlflow.log_param(\"model_name_tfidf\",vectorizer)\n",
    "\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"tfidf_max\", tfidf_max.item() if hasattr(tfidf_max, 'item') else tfidf_max)\n",
    "                mlflow.log_metric(\"qdrant_max\", qdrant_max)\n",
    "                if combined_scores:\n",
    "                    mlflow.log_metric(\"combined_max\", max(combined_scores, key=lambda x: x[1])[1])\n",
    "                \n",
    "                #log models\n",
    "                #mlflow.sklearn.log_model(sk_model=vectorizer_new, name=\"TFIDFVectorizer\")\n",
    "                #mlflow.sentence_transformers.log_model(model=model, name=\"SentenceTransformerModel\")\n",
    "\n",
    "                # Set tags\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "\n",
    "        # payload do Qdrant\n",
    "        qdrant_map = {\n",
    "            str(p.payload[\"_id\"]): p.payload for p in results.points\n",
    "        }\n",
    "\n",
    "        # resposta\n",
    "        applicant_info = {\n",
    "                \"_id\" : id,\n",
    "                \"nome\" : nome,\n",
    "                \"email\" : email,\n",
    "                \"telefone\":telefone,\n",
    "        }\n",
    "\n",
    "        top_vagas = []\n",
    "        for _id, score in top_matches:\n",
    "            payload = qdrant_map.get(_id, {})\n",
    "            top_vagas.append({\n",
    "                 \"_id\": _id,\n",
    "                \"titulo_vaga\": payload.get(\"titulo_vaga\", \"\"),\n",
    "                \"cliente\": payload.get(\"cliente\", \"\"),\n",
    "                \"score\": round(score, 3)\n",
    "            })\n",
    "\n",
    "        output = [{\"applicant\":applicant_info, \"top_vagas\":top_vagas}]\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        with mlflow.start_run(run_name=\"Applicants Match - FAILED\") as run:\n",
    "            mlflow.log_param(\"applicant_id\", applicant_id)\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"top_n\", top_n)\n",
    "            mlflow.log_param(\"version\", version)\n",
    "            mlflow.set_tag(\"status\", \"failed\")\n",
    "            mlflow.set_tag(\"error_message\", str(e))\n",
    "            mlflow.set_tag(\"error_traceback\", traceback.format_exc())\n",
    "        raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7-tech-challenge-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
